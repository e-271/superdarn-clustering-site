<!doctype html>

<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Creating the Toolkit</title>
  <meta name="author" content="Esther Robb">
  <link rel="stylesheet" href="css/foundation.css">
</head>

<body>
  <div class="grid-container">
    <div class="grid-x grid-padding-x">
      <div class="large-8 cell">
		<img href="docs/header.png"></img>
		<h3>Creating a machine learning toolkit</h3>

	       <h5>[5/30 - 6/8, 1.5 weeks]</h5>
		<ul>
			<li>Study the dataset to determine statistical information (Python StatsModel).</li>
			<li>Clean up code. Put in a virtual environment.</li>
			<li>Create a GitHub toolkit with the code.</li>
			<li>Produce online documentation.</li>
		</ul>

        <h3>Work Log</h3>
	    <p><b>Done:</b> Implement Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) as a performance measure.</p>
	    <p>With all 7 features and on all 16 beams, AIC and BIC will just keep decreasing (low score means better model) up to 100 clusters, where it becomes way too computationally expensive to be practical. However, with just 1-2 of the most Gaussian looking features, AIC and BIC show the best model fit for 5-10 clusters. </p>
	    <p>Some of the features look very Gaussian, like velocity and spectral width, and some don't like beam and power.</p>
	    <p>5-10 clusters seems to make the most physical sense, where 100 seems like it is overfitting. To make the Gaussian model make sense and not use a huge number of clusters to try to fit something not meant to be fit by a Gaussian, we are considering dropping the features that do not look Gaussian. Alternatively, they could be transformed using a method like Box Cox.</p>
	    <p>Next I will apply forward/backward selection using AIC and BIC to do feature selection, combined with some physical reasoning about what features make sense for GMM.</p>
	    <p><b>Done:</b> Create a poster for the SuperDARN workshop (6/3 thru 6/8). Use lots of graphs with good descriptions. Due 5/30.</p>
	    <p><a href="docs/robb_superdarn_clustering.pdf">Poster for SuperDARN workshop 2018</a></p>
	    <p><b>Done:</b> Test the algorithm on 2 datasets: SAS (high-latitude) and a midlatitude radar. Document and debug problems.</p>
	    <p>The poster above shows a comparison of SAS (high-latitude) vs. CVW (mid-latitude) on Feb 7 2018 (good data, no dual-frequency on this day). They are both doing better than the traditional model, but on CVW on that day some IS is being misclassified as GS on other beams that are not shown there (you can see evidence of this in Figure 10 at range gate 20 - there should not be a bump in both IS and GS in the same range gate).</p>
	    <p>Next steps here is to study a few days of data, and figure out a better evaluation criteria than what we are currently using (median |velocity| > 15 m/s). Some options are to use a ratio of high:low velocity like in Ribeiro et. al., or to base it on velocity and spectral width like the traditional method does.</p>
      </div>
    </div>
  </div>
  
  <script src="js/scripts.js"></script>
</body>
</html>


